{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPeraHOCfOdo",
        "outputId": "eb627c27-744a-4b46-b917-34fd249cf564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "19Qm9P0mrcXi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "mWK121zhvXQm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Lists to store images and labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Feature dictionary to specify the TFRecord structure\n",
        "feature_dictionary = {\n",
        "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'label_normal': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'image': tf.io.FixedLenFeature([], tf.string)  # Changed from 'image' to 'image_raw' as per previous suggestions\n",
        "}\n",
        "\n",
        "# Function to parse TFRecord examples\n",
        "def _parse_function(example):\n",
        "    parsed_example = tf.io.parse_single_example(example, feature_dictionary)\n",
        "    return parsed_example\n",
        "\n",
        "# Function to read and process data from TFRecord files\n",
        "def read_data(filename):\n",
        "    full_dataset = tf.data.TFRecordDataset(filename, num_parallel_reads=tf.data.experimental.AUTOTUNE)\n",
        "    full_dataset = full_dataset.shuffle(buffer_size=31000)\n",
        "    full_dataset = full_dataset.cache()\n",
        "\n",
        "    print(f\"Size of Dataset from {filename}: \", len(list(full_dataset)))\n",
        "\n",
        "    # Map the parsing function to the dataset\n",
        "    full_dataset = full_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    # Process each example in the dataset\n",
        "    for image_features in full_dataset:\n",
        "        # Decode the raw image string\n",
        "        image = tf.io.decode_raw(image_features['image'], tf.uint8)\n",
        "        image = tf.reshape(image, [299, 299])\n",
        "\n",
        "        # Optionally resize the image if needed\n",
        "        image = cv2.resize(image.numpy(), (100, 100))\n",
        "        image = cv2.merge([image, image, image])  # Ensure the image has 3 channels\n",
        "\n",
        "        # Append image and label to lists\n",
        "        images.append(image)\n",
        "        labels.append(image_features['label_normal'].numpy())\n",
        "\n",
        "# List of TFRecord filenames\n",
        "filenames=[\n",
        "    '/content/drive/My Drive/MY_DATA/training10_0/training10_0.tfrecords']#,\n",
        "#     '/content/drive/My Drive/MY_DATA/training10_1/training10_1.tfrecords',\n",
        "#     '/content/drive/My Drive/MY_DATA/training10_2/training10_2.tfrecords',\n",
        "#     '/content/drive/My Drive/MY_DATA/training10_3/training10_3.tfrecords',\n",
        "#     '/content/drive/My Drive/MY_DATA/training10_4/training10_4.tfrecords',\n",
        "# ]\n",
        "# Read data from each TFRecord file\n",
        "for file in filenames:\n",
        "    read_data(file)\n",
        "\n",
        "# Print the lengths of images and labels\n",
        "print(\"Total number of images:\", len(images))\n",
        "print(\"Total number of labels:\", len(labels))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2fSzIj-9lFPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc2c261-b04e-48da-c8ee-95f1e48c58c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of Dataset from /content/drive/My Drive/MY_DATA/training10_0/training10_0.tfrecords:  11177\n",
            "Total number of images: 11177\n",
            "Total number of labels: 11177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert images and labels to PyTorch tensors\n",
        "images_np = np.array(images, dtype=np.float32)  # Convert to NumPy array\n",
        "images_np /= 255.0\n",
        "images_tensor = torch.tensor(images_np).permute(0, 3, 1, 2)  # Change shape to (N, C, H, W)\n",
        "\n",
        "labels_np = np.array(labels)\n",
        "labels_tensor = torch.tensor(labels_np, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images_tensor.numpy(), labels_tensor.numpy(), test_size=0.2, random_state=42)\n",
        "\n",
        "# Create DataLoaders for the train and test sets\n",
        "train_dataset = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "BA3kuYBjgI7C"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the Multiscale DEQ Model with Implicit Differentiation\n",
        "class MultiscaleDEQModel(nn.Module):\n",
        "    def __init__(self, max_iterations=5, tolerance=1e-5):\n",
        "        super(MultiscaleDEQModel, self).__init__()\n",
        "\n",
        "        # Define three convolutional layers with different kernel sizes\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)  # 3x3 convolution\n",
        "        self.conv2 = nn.Conv2d(3, 16, kernel_size=5, padding=2)  # 5x5 convolution\n",
        "        self.conv3 = nn.Conv2d(3, 16, kernel_size=7, padding=3)  # 7x7 convolution\n",
        "        self.pool = nn.MaxPool2d(2)  # 2x2 pooling\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(48 * 50 * 50, 32)  # Adjusted based on the output from the convolutions\n",
        "        self.fc2 = nn.Linear(32, 1)  # Output layer for binary classification\n",
        "\n",
        "        self.max_iterations = max_iterations\n",
        "        self.tolerance = tolerance\n",
        "\n",
        "    def F(self, z, x):\n",
        "        # Compute features at different scales\n",
        "        scale1 = self.pool(self.relu(self.conv1(x)))  # Output: (B, 16, 50, 50)\n",
        "        scale2 = self.pool(self.relu(self.conv2(x)))  # Output: (B, 16, 50, 50)\n",
        "        scale3 = self.pool(self.relu(self.conv3(x)))  # Output: (B, 16, 50, 50)\n",
        "\n",
        "        # Concatenate the outputs from all scales\n",
        "        z_new = torch.cat((scale1, scale2, scale3), dim=1)  # Output: (B, 48, 50, 50)\n",
        "\n",
        "        # Flatten the concatenated output and apply fully connected layers\n",
        "        z_new = z_new.view(z_new.size(0), -1)  # Flatten to (B, 48 * 50 * 50)\n",
        "        z_new = self.relu(self.fc1(z_new))  # Fully connected layer\n",
        "        z_new = self.fc2(z_new)  # Output layer\n",
        "        return z_new\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize z as zeros\n",
        "        z = torch.zeros(x.size(0), 1).to(x.device)\n",
        "\n",
        "        # Iteratively find the fixed point\n",
        "        for _ in range(self.max_iterations):\n",
        "            z_new = self.F(z, x)\n",
        "            if torch.max(torch.abs(z_new - z)) < self.tolerance:\n",
        "                break\n",
        "            z = z_new\n",
        "\n",
        "        return z\n",
        "\n",
        "    def backward(self, x, z, grad_output):\n",
        "        \"\"\"\n",
        "        Implicit differentiation for DEQ: computes the gradient of the loss with respect to inputs.\n",
        "        \"\"\"\n",
        "        with torch.enable_grad():\n",
        "            z = z.detach().requires_grad_()\n",
        "            f_z = self.F(z, x)\n",
        "\n",
        "        # Compute Jacobian-vector product (JVP) for the implicit function.\n",
        "        # Here, grad_output comes from the gradient of the loss with respect to the output.\n",
        "        grad_z = torch.autograd.grad(f_z, z, grad_outputs=grad_output, retain_graph=True)[0]\n",
        "\n",
        "        # Compute gradient of the loss with respect to the input x.\n",
        "        grad_x = torch.autograd.grad(f_z, x, grad_outputs=grad_z, retain_graph=True)[0]\n",
        "\n",
        "        return grad_x\n",
        "\n",
        "# Instantiate the model, define loss, and optimizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MultiscaleDEQModel().to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()  # Suitable for binary classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Example training loop with progress bar\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    # Use tqdm to add a progress bar for each epoch\n",
        "    with tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as tepoch:\n",
        "        for batch_images, batch_labels in tepoch:\n",
        "            batch_images = batch_images.to(device)\n",
        "            batch_labels = batch_labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Clear gradients\n",
        "            outputs = model(batch_images)  # Forward pass using the implicit layer\n",
        "            loss = criterion(outputs, batch_labels)  # Compute loss\n",
        "\n",
        "            # Compute gradients using the backward method with implicit differentiation\n",
        "            loss.backward()  # Backpropagation for implicit differentiation\n",
        "            optimizer.step()  # Update weights\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            # Update progress bar with the current loss value\n",
        "            tepoch.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {epoch_loss/len(train_dataloader):.4f}')\n",
        "\n",
        "# Evaluation step\n",
        "model.eval()  # Set model to evaluation mode\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():  # No need to compute gradients during evaluation\n",
        "    for batch_images, batch_labels in test_dataloader:\n",
        "        batch_images = batch_images.to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "\n",
        "        outputs = model(batch_images)  # Forward pass\n",
        "        predicted = torch.sigmoid(outputs).round()  # Apply sigmoid and round to get predicted labels\n",
        "        total_correct += (predicted == batch_labels).sum().item()  # Count correct predictions\n",
        "        total_samples += batch_labels.size(0)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = total_correct / total_samples\n",
        "print(f'Accuracy on test set: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPSVVvf_fkA-",
        "outputId": "ab41204b-2712-4995-8f25-2be73d11db25"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/3: 100%|██████████| 280/280 [03:16<00:00,  1.42batch/s, loss=0.276]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Average Loss: 0.3743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 280/280 [03:12<00:00,  1.46batch/s, loss=0.257]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/3], Average Loss: 0.2847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 280/280 [03:21<00:00,  1.39batch/s, loss=0.0636]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/3], Average Loss: 0.2623\n",
            "Accuracy on test set: 89.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the Multiscale DEQ Model with Implicit Differentiation\n",
        "class MultiscaleDEQModel(nn.Module):\n",
        "    def __init__(self, max_iterations=5, tolerance=1e-5):\n",
        "        super(MultiscaleDEQModel, self).__init__()\n",
        "\n",
        "        # Define three convolutional layers with different kernel sizes\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)  # 3x3 convolution\n",
        "        self.conv2 = nn.Conv2d(3, 16, kernel_size=5, padding=2)  # 5x5 convolution\n",
        "        self.conv3 = nn.Conv2d(3, 16, kernel_size=7, padding=3)  # 7x7 convolution\n",
        "        self.pool = nn.MaxPool2d(2)  # 2x2 pooling\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(48 * 50 * 50, 32)  # Adjusted based on the output from the convolutions\n",
        "        self.fc2 = nn.Linear(32, 1)  # Output layer for binary classification\n",
        "\n",
        "        self.max_iterations = max_iterations\n",
        "        self.tolerance = tolerance\n",
        "\n",
        "    def F(self, z, x):\n",
        "        # Compute features at different scales\n",
        "        scale1 = self.pool(self.relu(self.conv1(x)))  # Output: (B, 16, 50, 50)\n",
        "        scale2 = self.pool(self.relu(self.conv2(x)))  # Output: (B, 16, 50, 50)\n",
        "        scale3 = self.pool(self.relu(self.conv3(x)))  # Output: (B, 16, 50, 50)\n",
        "\n",
        "        # Concatenate the outputs from all scales\n",
        "        z_new = torch.cat((scale1, scale2, scale3), dim=1)  # Output: (B, 48, 50, 50)\n",
        "\n",
        "        # Flatten the concatenated output and apply fully connected layers\n",
        "        z_new = z_new.view(z_new.size(0), -1)  # Flatten to (B, 48 * 50 * 50)\n",
        "        z_new = self.relu(self.fc1(z_new))  # Fully connected layer\n",
        "        z_new = self.fc2(z_new)  # Output layer\n",
        "        return z_new\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize z as zeros\n",
        "        z = torch.zeros(x.size(0), 1).to(x.device)\n",
        "\n",
        "        # Iteratively find the fixed point\n",
        "        for _ in range(self.max_iterations):\n",
        "            z_new = self.F(z, x)\n",
        "            if torch.max(torch.abs(z_new - z)) < self.tolerance:\n",
        "                break\n",
        "            z = z_new\n",
        "\n",
        "        return z\n",
        "\n",
        "    def backward(self, x, z, grad_output):\n",
        "        \"\"\"\n",
        "        Implicit differentiation for DEQ: computes the gradient of the loss with respect to inputs.\n",
        "        \"\"\"\n",
        "        with torch.enable_grad():\n",
        "            z = z.detach().requires_grad_()\n",
        "            f_z = self.F(z, x)\n",
        "\n",
        "        # Compute Jacobian-vector product (JVP) for the implicit function.\n",
        "        # Here, grad_output comes from the gradient of the loss with respect to the output.\n",
        "        grad_z = torch.autograd.grad(f_z, z, grad_outputs=grad_output, retain_graph=True)[0]\n",
        "\n",
        "        # Compute gradient of the loss with respect to the input x.\n",
        "        grad_x = torch.autograd.grad(f_z, x, grad_outputs=grad_z, retain_graph=True)[0]\n",
        "\n",
        "        return grad_x\n",
        "\n",
        "# Instantiate the model, define loss, and optimizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MultiscaleDEQModel().to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()  # Suitable for binary classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Example training loop with progress bar\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    # Use tqdm to add a progress bar for each epoch\n",
        "    with tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as tepoch:\n",
        "        for batch_images, batch_labels in tepoch:\n",
        "            batch_images = batch_images.to(device)\n",
        "            batch_labels = batch_labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Clear gradients\n",
        "            outputs = model(batch_images)  # Forward pass using the implicit layer\n",
        "            loss = criterion(outputs, batch_labels)  # Compute loss\n",
        "\n",
        "            # Compute gradients using the backward method with implicit differentiation\n",
        "            loss.backward()  # Backpropagation for implicit differentiation\n",
        "            optimizer.step()  # Update weights\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            # Update progress bar with the current loss value\n",
        "            tepoch.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {epoch_loss/len(train_dataloader):.4f}')\n",
        "\n",
        "# Evaluation step\n",
        "model.eval()  # Set model to evaluation mode\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():  # No need to compute gradients during evaluation\n",
        "    for batch_images, batch_labels in test_dataloader:\n",
        "        batch_images = batch_images.to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "\n",
        "        outputs = model(batch_images)  # Forward pass\n",
        "        predicted = torch.sigmoid(outputs).round()  # Apply sigmoid and round to get predicted labels\n",
        "        total_correct += (predicted == batch_labels).sum().item()  # Count correct predictions\n",
        "        total_samples += batch_labels.size(0)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = total_correct / total_samples\n",
        "print(f'Accuracy on test set: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj11X8zgiJmE",
        "outputId": "ae2ddb17-d956-4c5a-c03b-2561efc5c380"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 280/280 [03:20<00:00,  1.39batch/s, loss=0.366]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Average Loss: 0.3529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2: 100%|██████████| 280/280 [03:15<00:00,  1.43batch/s, loss=0.572]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/2], Average Loss: 0.2799\n",
            "Accuracy on test set: 87.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the Multiscale DEQ Model with Implicit Differentiation\n",
        "class MultiscaleDEQModel(nn.Module):\n",
        "    def __init__(self, max_iterations=5, tolerance=1e-5):\n",
        "        super(MultiscaleDEQModel, self).__init__()\n",
        "\n",
        "        # Define three convolutional layers with different kernel sizes\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)  # 3x3 convolution\n",
        "        self.conv2 = nn.Conv2d(3, 16, kernel_size=5, padding=2)  # 5x5 convolution\n",
        "        self.conv3 = nn.Conv2d(3, 16, kernel_size=7, padding=3)  # 7x7 convolution\n",
        "        self.pool = nn.MaxPool2d(2)  # 2x2 pooling\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(48 * 50 * 50, 32)  # Adjusted based on the output from the convolutions\n",
        "        self.fc2 = nn.Linear(32, 1)  # Output layer for binary classification\n",
        "\n",
        "        self.max_iterations = max_iterations\n",
        "        self.tolerance = tolerance\n",
        "\n",
        "    def F(self, z, x):\n",
        "        # Compute features at different scales\n",
        "        scale1 = self.pool(self.relu(self.conv1(x)))  # Output: (B, 16, 50, 50)\n",
        "        scale2 = self.pool(self.relu(self.conv2(x)))  # Output: (B, 16, 50, 50)\n",
        "        scale3 = self.pool(self.relu(self.conv3(x)))  # Output: (B, 16, 50, 50)\n",
        "\n",
        "        # Concatenate the outputs from all scales\n",
        "        z_new = torch.cat((scale1, scale2, scale3), dim=1)  # Output: (B, 48, 50, 50)\n",
        "\n",
        "        # Flatten the concatenated output and apply fully connected layers\n",
        "        z_new = z_new.view(z_new.size(0), -1)  # Flatten to (B, 48 * 50 * 50)\n",
        "        z_new = self.relu(self.fc1(z_new))  # Fully connected layer\n",
        "        z_new = self.fc2(z_new)  # Output layer\n",
        "        return z_new\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize z as zeros\n",
        "        z = torch.zeros(x.size(0), 1).to(x.device)\n",
        "\n",
        "        # Iteratively find the fixed point\n",
        "        for _ in range(self.max_iterations):\n",
        "            z_new = self.F(z, x)\n",
        "            if torch.max(torch.abs(z_new - z)) < self.tolerance:\n",
        "                break\n",
        "            z = z_new\n",
        "\n",
        "        return z\n",
        "\n",
        "    def backward(self, x, z, grad_output):\n",
        "        \"\"\"\n",
        "        Implicit differentiation for DEQ: computes the gradient of the loss with respect to inputs.\n",
        "        \"\"\"\n",
        "        with torch.enable_grad():\n",
        "            z = z.detach().requires_grad_()\n",
        "            f_z = self.F(z, x)\n",
        "\n",
        "        # Compute Jacobian-vector product (JVP) for the implicit function.\n",
        "        # Here, grad_output comes from the gradient of the loss with respect to the output.\n",
        "        grad_z = torch.autograd.grad(f_z, z, grad_outputs=grad_output, retain_graph=True)[0]\n",
        "\n",
        "        # Compute gradient of the loss with respect to the input x.\n",
        "        grad_x = torch.autograd.grad(f_z, x, grad_outputs=grad_z, retain_graph=True)[0]\n",
        "\n",
        "        return grad_x\n",
        "\n",
        "# Instantiate the model, define loss, and optimizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MultiscaleDEQModel().to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()  # Suitable for binary classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Example training loop with progress bar\n",
        "num_epochs = 1\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    # Use tqdm to add a progress bar for each epoch\n",
        "    with tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as tepoch:\n",
        "        for batch_images, batch_labels in tepoch:\n",
        "            batch_images = batch_images.to(device)\n",
        "            batch_labels = batch_labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Clear gradients\n",
        "            outputs = model(batch_images)  # Forward pass using the implicit layer\n",
        "            loss = criterion(outputs, batch_labels)  # Compute loss\n",
        "\n",
        "            # Compute gradients using the backward method with implicit differentiation\n",
        "            loss.backward()  # Backpropagation for implicit differentiation\n",
        "            optimizer.step()  # Update weights\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            # Update progress bar with the current loss value\n",
        "            tepoch.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {epoch_loss/len(train_dataloader):.4f}')\n",
        "\n",
        "# Evaluation step\n",
        "model.eval()  # Set model to evaluation mode\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():  # No need to compute gradients during evaluation\n",
        "    for batch_images, batch_labels in test_dataloader:\n",
        "        batch_images = batch_images.to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "\n",
        "        outputs = model(batch_images)  # Forward pass\n",
        "        predicted = torch.sigmoid(outputs).round()  # Apply sigmoid and round to get predicted labels\n",
        "        total_correct += (predicted == batch_labels).sum().item()  # Count correct predictions\n",
        "        total_samples += batch_labels.size(0)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = total_correct / total_samples\n",
        "print(f'Accuracy on test set: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVHGlDcwwNMa",
        "outputId": "6b978362-445e-4ac8-93a2-fbb96713da20"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1: 100%|██████████| 280/280 [03:14<00:00,  1.44batch/s, loss=0.142]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Average Loss: 0.3309\n",
            "Accuracy on test set: 87.08%\n"
          ]
        }
      ]
    }
  ]
}